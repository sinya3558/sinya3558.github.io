---
title: "ì‚¬ì „ í•™ìŠµ ëª¨ë¸ Fine Tuning (2)"
description: "ì‚¬ì „ í•™ìŠµëœ ResNet ëª¨ë¸ì„ CIFAR-10 ë°ì´í„°ì…‹ì— ë§ê²Œ Fine Tuning í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ì •ë¦¬í•œ ì‹¤ìŠµ ê°€ì´ë“œ"
author: Seunga Kim
date: 2025-11-13
categories: [Deep Learning]
tags: [Computer Vision, Image Classification]
image: /assets/img/dl.png
toc: true
toc_label: "Table of Contents"
comments: false
---

# 14. VGGNet ê³¼ ResNet

> ê°•ì˜ ì£¼ì œ : ê°•ë ¥í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ë“¤ì˜ ì•„í‚¤í…ì²˜ ë° í•µì‹¬ êµ¬ì¡° (Residual Block, Skip Connection) ë¥¼ ì´í•´í•˜ê³ , ì´ë¥¼ í†µí•´ ë” ë³µì¡í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ë° ì¸ì‹ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµ

1. VGG16, VGG19 ì˜ êµ¬ì¡°ì™€ íŠ¹ì§•
2. ResNet ì˜ êµ¬ì¡°ì™€ íŠ¹ì§•
    - Residual connection == skip connection ê±°ì˜ ë‹¤ ì”€. skip connection ì•ˆë“¤ì–´ê°€ëŠ”ë°ê°€ ì—†ì–´
3. Model degradation ë¬¸ì œì™€ skip connection
4. Pretrained ResNet ëª¨ë¸ì„ ì´ìš©í•œ CIFAR-10 dataset ì˜ìƒë¶„ë¥˜
5. Pretrained VGG19 ëª¨ë¸ì„ ì´ìš©í•œ CIFAR-10 dataset ì˜ìƒë¶„ë¥˜
6. Pretrained ëª¨ë¸ layer êµì²´

---

## 14-2. ResNet ì˜ êµ¬ì¡°ì™€ íŠ¹ì§• (project 1 ë•Œë¬¸ì— ì–˜ ë¨¼ì €)

>  skip connection == residual connection ì€ ê¹Šì€ ì‹ ê²½ë§ ëª¨ë¸ì— ê±°ì˜ ë‹¤ ì“°ì¸ë‹¤

- ì´ê±¸ ì™œ ì“°ëŠ”ê°€?
    - ë ˆì´ì–´ë¥¼ ê¹Šê²Œ ìŒ“ìœ¼ë©´ ìŒ“ì„ìˆ˜ë¡, ëª¨ë¸ degradation ë¬¸ì œ ë°œìƒ 
    - íš¨ìœ¨ì„±, ì„±ì ì„ ì¢‹ê²Œ ë§Œë“¤ì–´ ì£¼ê¸°ìœ„í•´ **ë°˜ë“œì‹œ residual(skip) connection í•„ìš”**

![image.png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/image.png) 


- ê¹Šê²Œ ìŒ“ì•„ë„ ë¬¸ì œê°€ ì•ˆìƒê¹€

### Residual block / Bottleneck ì˜ êµ¬ì¡°

![image-4.png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/image-4.png)  ![image-3.png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/image-3.png)

- Standard Residual block
    - í•˜ë‚˜ ë³µì‚¬í•´ ë‘” ë‹¤ìŒì—, ë³µì‚¬í•´ë‘” ì• ë¥¼ ë‚˜ì¤‘ì— ë”í•´ì¤Œ

- Bottleneck block
    - ë ˆì´ì–´ 50 ì¸µ ì´ìƒ ìŒ“ì„ ë•Œ, ì—°ì‚°ëŸ‰ ì¤„ì´ê³  íš¨ìœ¨ ë†’ì´ê¸° ìœ„í•´ì„œ ì‚¬ìš©

---

## ResNet ì‹¤ìŠµ


```python
 !pip install torchviz torchinfo
```




```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import torch
from torch import nn, optim
import torch.nn.functional as F
from torchvision import transforms, datasets, models
from torch.utils.data import DataLoader

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("device = ", device)
```

    device =  cuda
    


```python
# plot default setting
plt.rcParams['font.size'] = 8
plt.rcParams['figure.figsize'] = (4, 4)
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.linestyle'] = ":"
plt.rcParams['axes.unicode_minus'] = False
```


```python
!git clone https://github.com/wikibook/pythonlibs.git
```

    fatal: destination path 'pythonlibs' already exists and is not an empty directory.
    


```python
from pythonlibs.torch_lib1 import *
```

# ResNet ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°

#### 1. (ëª¨ë¸ ë¶€ë¥´ê¸° ì „ì— ) ë¶„ë¥˜ ë¼ë²¨ ë¨¼ì € ì§€ì •í•˜ê¸°


```python
## ëª¨ë¸ ë¶€ë¥´ê¸° ì „ì—! classes ë¨¼ì € ì •ì˜
classes = ('plane', 'car', 'bird', 'cat', 'deer',
            'dog', 'frog', 'horse', 'ship', 'truck')    # CIFAR-10

num_classes = len(classes)  # 10 ê°œ
```

#### 2. (ëª¨ë¸ ë¶€ë¥´ê¸° ì „ì—) ë°ì´í„° ë‹¤ìš´ë¡œë“œ

- 2-1. *transforms ì •ì˜* ê°€ ê°€ì¥ ë¨¼ì € í•´ì•¼í•  ì¼
- 2-2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
- 2-3. batch size ë¡œ ë°ì´í„° ë‚˜ëˆ„ê¸° by DataLoader


```python
## 2-1. transforms ì •ì˜
# train 
transform_train = transforms.Compose(
    # ë¦¬ìŠ¤íŠ¸
    [
        # CIFAR-10 ë°ì´í„° ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” 32x32 -> ë„ˆë¬´ ì‘ê¸° ë•Œë¬¸ì— -> resize ì§„í–‰ (112x112)
        transforms.Resize(112),
        transforms.RandomRotation(30),   # ê°ë„ 30 ìœ¼ë¡œ ë¡œí…Œì´ì…˜
        transforms.RandomHorizontalFlip(0.5),
        transforms.ToTensor(),
        transforms.Normalize(0.5, 0.5)
    ]
)


# test
transform_test = transforms.Compose(
    # ë¦¬ìŠ¤íŠ¸
    [
        # CIFAR-10 ë°ì´í„° ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” 32x32 -> ë„ˆë¬´ ì‘ê¸° ë•Œë¬¸ì— -> resize ì§„í–‰ (112x112)
        transforms.Resize(112),

        ## test ì—ì„œëŠ” í•„ìš”ì—†ëŠ” ë¶€ë¶„
        # transforms.RandomRotation(30),   # ê°ë„ 30 ìœ¼ë¡œ ë¡œí…Œì´ì…˜
        # transforms.RandomHorizontalFlip(0.5),

        transforms.ToTensor(),
        transforms.Normalize(0.5, 0.5)
    ]
)

```


```python
## 2-2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë°›ê¸°
data_root = "./data"

## (1) Train
train_set = datasets.CIFAR10(
    data_root,
    True,
    transform_train,
    download = True
)

## (2) Test
test_set = datasets.CIFAR10(
    data_root,
    False,
    transform_train,
    download = True
)
```



```python
## 2-3. batch_size ë¡œ ë°ì´í„° ë‚˜ëˆ„ê¸°

# batch
batch_size = 100

# (1) Train
train_loader = DataLoader(
    dataset = train_set,
    batch_size = batch_size,
    shuffle = True
)

# (2) Test
test_loader = DataLoader(
    dataset = test_set,
    batch_size = batch_size,
    shuffle = False
)
```

#### (Optional) ëª¨ë¸ ë¶ˆëŸ¬ì„œ í•™ìŠµ ì‹œí‚¤ê¸° ì „, raw datasets (CIFAR-10) í™•ì¸

- `show_images_labels()`


```python
show_images_labels(test_loader, classes, None, None)
```


    
![png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/14_VGG_ResNet_ê°œë¡ _13_0.png)
    


## 3. ì´ì œ ì°ìœ¼ë¡œ ResNet ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°

![image-2.png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/image-2.png)

- ResNet ìŒ“ì—¬ìˆëŠ” ë ˆì´ì–´ì¸µë“¤ì„ ë³´ë©´, skip connection ì´ ì „ì— *ë˜‘ê°™ì€ ë¸”ëŸ­ì´* **ë‘ ë²ˆì”© ë°˜ë³µ**ëœë‹¤


```python
# weight ë¨¼ì € ê°€ì ¸ì˜¤ê¸°
weight = models.ResNet18_Weights.IMAGENET1K_V1

# model ë¶ˆëŸ¬ì˜¤ê¸°
resnet18 = models.resnet18(weights = weight)

print("resnet18 = ", resnet18)  # ëª¨ë¸ ë„¤íŠ¸ì›Œí¬ ì¶œë ¥í•´ë³´ê¸°

'''
skip connection : ì´ë¯¸ì§€ ì¹´í”¼í•´ ë’€ë‹¤ê°€ ë ˆì´ì–´ì— ë„ë‹¬í•˜ë©´ ë³µë¶™í•´ì£¼ëŠ”ê±° 

- conv ë¸”ëŸ­ë„ ë‘ ë²ˆì”© ë°˜ë³µëœë‹¤? -> ë°˜ë³µë˜ì„œ ë¶ˆë¦¬ë‹ˆê¹Œ ëª¨ë“ˆí™” (nn.Sequential) í•´ë‘ë©´ ì¢‹ìŒ!
- ì˜ˆ:
(0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
'''
```



```python
from torchinfo import summary

summary(resnet18, (100, 3, 112, 112))    # [batch_size, channels, height, width]

# ê·¼ë° ì´ë ‡ê²Œ summary ë¡œ ë½‘ìœ¼ë©´ skip connection ê°™ì€ ê²½ìš°, ë³´ì´ì§€ ì•ŠìŒ -> í•œê³„
## ë§¨ ë§ˆì§€ë§‰ì—” ë¬´ì¡°ê±´ AdaptiveAvgPool2d ë“¤ì–´ê°€ ìˆë‹¤?
# ğŸ‘‰ ì´ adaptiveAvgPool ë•ë¶„ì— ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ ì–´ë–¤ê±°ë“  ë‹¤ ë„£ì„ ìˆ˜ ìˆìŒ. ì§œí”¼ 1x1 ê°€ ë˜ë‹ˆê¹
## Total params: 11,689,512 ğŸ‘‰ íŒŒë¼ë¯¸í„° ìˆ˜ VGG ì˜ 1/10, ê·¼ë°! ì„±ëŠ¥ì€ ë” ì¢‹ìŒ 
```




    ==========================================================================================
    Layer (type:depth-idx)                   Output Shape              Param #
    ==========================================================================================
    ResNet                                   [100, 1000]               --
    â”œâ”€Conv2d: 1-1                            [100, 64, 56, 56]         9,408
    â”œâ”€BatchNorm2d: 1-2                       [100, 64, 56, 56]         128
    â”œâ”€ReLU: 1-3                              [100, 64, 56, 56]         --
    â”œâ”€MaxPool2d: 1-4                         [100, 64, 28, 28]         --
    â”œâ”€Sequential: 1-5                        [100, 64, 28, 28]         --
    â”‚    â””â”€BasicBlock: 2-1                   [100, 64, 28, 28]         --
    â”‚    â”‚    â””â”€Conv2d: 3-1                  [100, 64, 28, 28]         36,864
    â”‚    â”‚    â””â”€BatchNorm2d: 3-2             [100, 64, 28, 28]         128
    â”‚    â”‚    â””â”€ReLU: 3-3                    [100, 64, 28, 28]         --
    â”‚    â”‚    â””â”€Conv2d: 3-4                  [100, 64, 28, 28]         36,864
    â”‚    â”‚    â””â”€BatchNorm2d: 3-5             [100, 64, 28, 28]         128
    â”‚    â”‚    â””â”€ReLU: 3-6                    [100, 64, 28, 28]         --
    â”‚    â””â”€BasicBlock: 2-2                   [100, 64, 28, 28]         --
    â”‚    â”‚    â””â”€Conv2d: 3-7                  [100, 64, 28, 28]         36,864
    â”‚    â”‚    â””â”€BatchNorm2d: 3-8             [100, 64, 28, 28]         128
    â”‚    â”‚    â””â”€ReLU: 3-9                    [100, 64, 28, 28]         --
    â”‚    â”‚    â””â”€Conv2d: 3-10                 [100, 64, 28, 28]         36,864
    â”‚    â”‚    â””â”€BatchNorm2d: 3-11            [100, 64, 28, 28]         128
    â”‚    â”‚    â””â”€ReLU: 3-12                   [100, 64, 28, 28]         --
    â”œâ”€Sequential: 1-6                        [100, 128, 14, 14]        --
    â”‚    â””â”€BasicBlock: 2-3                   [100, 128, 14, 14]        --
    â”‚    â”‚    â””â”€Conv2d: 3-13                 [100, 128, 14, 14]        73,728
    â”‚    â”‚    â””â”€BatchNorm2d: 3-14            [100, 128, 14, 14]        256
    â”‚    â”‚    â””â”€ReLU: 3-15                   [100, 128, 14, 14]        --
    â”‚    â”‚    â””â”€Conv2d: 3-16                 [100, 128, 14, 14]        147,456
    â”‚    â”‚    â””â”€BatchNorm2d: 3-17            [100, 128, 14, 14]        256
    â”‚    â”‚    â””â”€Sequential: 3-18             [100, 128, 14, 14]        8,448
    â”‚    â”‚    â””â”€ReLU: 3-19                   [100, 128, 14, 14]        --
    â”‚    â””â”€BasicBlock: 2-4                   [100, 128, 14, 14]        --
    â”‚    â”‚    â””â”€Conv2d: 3-20                 [100, 128, 14, 14]        147,456
    â”‚    â”‚    â””â”€BatchNorm2d: 3-21            [100, 128, 14, 14]        256
    â”‚    â”‚    â””â”€ReLU: 3-22                   [100, 128, 14, 14]        --
    â”‚    â”‚    â””â”€Conv2d: 3-23                 [100, 128, 14, 14]        147,456
    â”‚    â”‚    â””â”€BatchNorm2d: 3-24            [100, 128, 14, 14]        256
    â”‚    â”‚    â””â”€ReLU: 3-25                   [100, 128, 14, 14]        --
    â”œâ”€Sequential: 1-7                        [100, 256, 7, 7]          --
    â”‚    â””â”€BasicBlock: 2-5                   [100, 256, 7, 7]          --
    â”‚    â”‚    â””â”€Conv2d: 3-26                 [100, 256, 7, 7]          294,912
    â”‚    â”‚    â””â”€BatchNorm2d: 3-27            [100, 256, 7, 7]          512
    â”‚    â”‚    â””â”€ReLU: 3-28                   [100, 256, 7, 7]          --
    â”‚    â”‚    â””â”€Conv2d: 3-29                 [100, 256, 7, 7]          589,824
    â”‚    â”‚    â””â”€BatchNorm2d: 3-30            [100, 256, 7, 7]          512
    â”‚    â”‚    â””â”€Sequential: 3-31             [100, 256, 7, 7]          33,280
    â”‚    â”‚    â””â”€ReLU: 3-32                   [100, 256, 7, 7]          --
    â”‚    â””â”€BasicBlock: 2-6                   [100, 256, 7, 7]          --
    â”‚    â”‚    â””â”€Conv2d: 3-33                 [100, 256, 7, 7]          589,824
    â”‚    â”‚    â””â”€BatchNorm2d: 3-34            [100, 256, 7, 7]          512
    â”‚    â”‚    â””â”€ReLU: 3-35                   [100, 256, 7, 7]          --
    â”‚    â”‚    â””â”€Conv2d: 3-36                 [100, 256, 7, 7]          589,824
    â”‚    â”‚    â””â”€BatchNorm2d: 3-37            [100, 256, 7, 7]          512
    â”‚    â”‚    â””â”€ReLU: 3-38                   [100, 256, 7, 7]          --
    â”œâ”€Sequential: 1-8                        [100, 512, 4, 4]          --
    â”‚    â””â”€BasicBlock: 2-7                   [100, 512, 4, 4]          --
    â”‚    â”‚    â””â”€Conv2d: 3-39                 [100, 512, 4, 4]          1,179,648
    â”‚    â”‚    â””â”€BatchNorm2d: 3-40            [100, 512, 4, 4]          1,024
    â”‚    â”‚    â””â”€ReLU: 3-41                   [100, 512, 4, 4]          --
    â”‚    â”‚    â””â”€Conv2d: 3-42                 [100, 512, 4, 4]          2,359,296
    â”‚    â”‚    â””â”€BatchNorm2d: 3-43            [100, 512, 4, 4]          1,024
    â”‚    â”‚    â””â”€Sequential: 3-44             [100, 512, 4, 4]          132,096
    â”‚    â”‚    â””â”€ReLU: 3-45                   [100, 512, 4, 4]          --
    â”‚    â””â”€BasicBlock: 2-8                   [100, 512, 4, 4]          --
    â”‚    â”‚    â””â”€Conv2d: 3-46                 [100, 512, 4, 4]          2,359,296
    â”‚    â”‚    â””â”€BatchNorm2d: 3-47            [100, 512, 4, 4]          1,024
    â”‚    â”‚    â””â”€ReLU: 3-48                   [100, 512, 4, 4]          --
    â”‚    â”‚    â””â”€Conv2d: 3-49                 [100, 512, 4, 4]          2,359,296
    â”‚    â”‚    â””â”€BatchNorm2d: 3-50            [100, 512, 4, 4]          1,024
    â”‚    â”‚    â””â”€ReLU: 3-51                   [100, 512, 4, 4]          --
    â”œâ”€AdaptiveAvgPool2d: 1-9                 [100, 512, 1, 1]          --
    â”œâ”€Linear: 1-10                           [100, 1000]               513,000
    ==========================================================================================
    Total params: 11,689,512
    Trainable params: 11,689,512
    Non-trainable params: 0
    Total mult-adds (G): 48.54
    ==========================================================================================
    Input size (MB): 15.05
    Forward/backward pass size (MB): 1009.64
    Params size (MB): 46.76
    Estimated Total Size (MB): 1071.46
    ==========================================================================================




```python
print(resnet18) # ë„¤íŠ¸ì›Œí¬ ì¶œë ¥

# ë§¨ ë§ˆì§€ë§‰ fc ë ˆì´ì–´ ğŸ‘‡
# (fc): Linear(in_features=512, out_features=1000, bias=True)
## ğŸ«¸ ì‚¬ìš©í•˜ëŠ” ëª©ì ì— ë§ê²Œ fc ë ˆì´ì–´ë¥¼ ìˆ˜ì •í•´ì•¼í•¨
```

    ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      ...
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=1000, bias=True)
    

### ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì˜ ë§ˆì§€ë§‰ FC layer ì— ì ‘ê·¼í•´ ìˆ˜ì •í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì.

#### ğŸ‘€ ì ‘ê·¼ ë°©ë²• :

1. ë ˆì´ì–´ ì´ë¦„ìœ¼ë¡œ ì ‘ê·¼í•˜ê¸° : print(`resnet18.fc`)

2. ë ˆì´ì–´ íŠ¹ì • íŒŒë¼ë¯¸í„°ì— ì ‘ê·¼í•˜ê³  ì‹¶ì„ ë•Œ : print(`resnet18.fc.in_features`)


```python

print(resnet18.fc)
```

    ê²°ê³¼ : Linear(in_features=512, out_features=1000, bias=True)




```python
print(resnet18.fc.in_features) # 512
```




    ê²°ê³¼ : 512

#### ì™œ íŠ¹ì • ë ˆì´ì–´ì— ì ‘ê·¼í•´ì•¼í•˜ëŠ”ê°€?

- ìš°ë¦¬ê°€ ì‚¬ìš©í•  ë°ì´í„° ì…‹ : CIFAR-10 -> í´ë˜ìŠ¤ ë¼ë²¨ `10 ê°œ`
- ResNet ì´ ì‚¬ì „ í•™ìŠµì‹œí‚¬ ë•Œ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ : ImageNet -> í´ë˜ìŠ¤ ë¼ë²¨ `1000 ê°œ`

> ì¶œë ¥ ë…¸ë“œ ê°œìˆ˜ ë¶ˆì¼ì¹˜ í˜„ìƒì´ ë‚˜íƒ€ë‚˜ì„œ ì—ëŸ¬ ë°œìƒí•˜ê²Œ ëœë‹¤. ëª¨ë¸ì˜ ì¶œë ¥ ê°’ì„ ë‚´ ìƒí™©ì— ë§ê²Œ êµì²´ í•„ìš”

#### ğŸ™‹ğŸ»â€â™€ï¸ ëª¨ë¸ ì¶œë ¥ ê°’ ìˆ˜ì •í•˜ê¸° : in_features  ë˜ëŠ” my_in_features ë¡œ ì§€ì •

```python
my_in_features = resnet18.fc.in_features

resnet18.fc = nn.Linear(my_in_features, num_classes)   

print(resnet18) # ìˆ˜ì • í›„, ê²°ê³¼ í™•ì¸ ìš©
```

    ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        
      ...
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    

#### ğŸ“¢ Fc ë ˆì´ì–´ ìˆ˜ì • í™•ì¸ ê²°ê³¼

- ìˆ˜ì • ì „ :
    - (fc): Linear(in_features=512, `out_features=1000`, bias=True)

- ìˆ˜ì • í›„ :
    - (fc): Linear(in_features=512, `out_features=10`, bias=True)

---

### ResNet ì´ ì–¼ë§ˆë‚˜ ë³µì¡í•˜ëƒë©´ ë§ì´ì£ ?

- make_dot ì‚¬ìš©í•´ì„œ ResNet ì‹œê°í™”í•˜ê¸°


```python
## make_dot -> ì´ê±° í•˜ë ¤ë©´ scalar ë¡œ ë°”ê¿”ì•¼í•œë‹¤ëŠ”ë””?
from torchviz import make_dot

# ëª¨ë¸ì„ gpu ë¡œ ë³´ë‚¸ ì ì´ ì—†ì–´! -> cpu ì— ìˆì–´!
resnet18 = resnet18.to(device)  # gpu ë¡œ ë³´ë‚´ë²„ë¦¬ê¸°
criterion = nn.CrossEntropyLoss()
loss = eval_loss(test_loader, device, resnet18, criterion)


g = make_dot(loss, params = dict(resnet18.named_parameters()))
display(g)
```


    
![svg](../assets/img/14_VGG_ResNet_ê°œë¡ _files/14_VGG_ResNet_ê°œë¡ _25_0.svg)
    


- ì¤‘ê°„ì¤‘ê°„ì— `skip connection` í™•ì¸! ë³´ì´ê¸´ ë³´ì´ëŠ”ë° ìŒ... ë§¤ìš° ë³µì¡í•˜ë‹¤. ë­ê°€ ë­”ì§€ ëª¨ë¥´ê² ë‹¤

## 4. ResNet í•™ìŠµí•˜ê¸°

- `fine tuning` : ë‚¨ì´ ì¨ë†“ì€ ëª¨ë¸ ê°€ì ¸ë‹¤ê°€ ë‚´ê°€ í•„ìš”í•œ ê±°ì— ë§ì¶°ì„œ íŠœë‹í•´ì„œ ì“°ëŠ”ê±°


```python
## ResNet NETWORK ì¤€ë¹„ ì™„ë£Œ!

## Fine tuning -> ìˆëŠ” ëª¨ë¸ ê°€ì ¸ë‹¤ê°€ ì“°ëŠ”ê±°
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(resnet18.parameters(), momentum = 0.9)

num_epochs = 3
history = np.zeros((0, 5))  # ìˆœì„œë¥¼ ìê¾¸ ë°”ê¿”ì“°ë„¤ ë‚˜...ã… 

# fit í•¨ìˆ˜ ì˜¬í…Œì•¼ë¶ˆëŸ¬ì˜¬í…Œì•¼
history = fit(resnet18, optimizer, criterion, num_epochs, train_loader, test_loader, device, history)
```


      0%|          | 0/500 [00:00<?, ?it/s]


    Epoch [1/3], loss: 0.00787 acc: 0.73298 val_loss: 0.00425, val_acc: 0.85400
    


      0%|          | 0/500 [00:00<?, ?it/s]


    Epoch [2/3], loss: 0.00366 acc: 0.87578 val_loss: 0.00332, val_acc: 0.88620
    


      0%|          | 0/500 [00:00<?, ?it/s]


    Epoch [3/3], loss: 0.00290 acc: 0.90158 val_loss: 0.00295, val_acc: 0.89880
    

- ì™€... ì„±ëŠ¥ ê²€ì¦ ë°ì´í„°ë¡œ 89%
- ì„±ëŠ¥ ì¢‹ê¸´ ì¢‹êµ¬ë‚˜ 18ê°œë§Œ ì¼ëŠ”ë°ë„

## 5. ResNet í•™ìŠµ ê²°ê³¼ í‰ê°€


```python
# ê²°ê³¼ ìš”ì•½
evaluate_history(history)
```

    Init Status : Loss : 0.00425  Acc : 0.85400
    Final Status : Loss : 0.00295 Acc : 0.89880
    


    
![png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/14_VGG_ResNet_ê°œë¡ _31_1.png)
    



    
![png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/14_VGG_ResNet_ê°œë¡ _31_2.png)
    


## 6. ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ ì´ë¯¸ì§€ë¡œ í™•ì¸í•˜ê¸°

- `show_images_labels()`


```python
show_images_labels(test_loader, classes, resnet18, device)
```


    
![png](../assets/img/14_VGG_ResNet_ê°œë¡ _files/14_VGG_ResNet_ê°œë¡ _33_0.png)
    

