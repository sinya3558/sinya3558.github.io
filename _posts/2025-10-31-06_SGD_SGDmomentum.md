---
layout: single
title:  "SGD vs SGD w.ëª¨ë©˜í…€ ë¹„êµ"
description: "ipynb íŒŒì¼ì„ .md ë¡œ ë³€í™˜ì‹œì¼œ ì˜¬ë ¤ë³´ëŠ” í…ŒìŠ¤íŠ¸ ê¸€"
date: 2025-10-31
categories: [Deep Learning]
tag: [Optimization, Gradient Descent]
toc: true
author_profile: True
---

# (1) ê²½ì‚¬í•˜ê°•ë²•(SGD) ê³¼ (2) ëª¨ë©˜í…€ì„ ì ìš©í•œ SGD ë¹„êµ



ê¸°ë³¸ **ê²½ì‚¬í•˜ê°•ë²•(Stochastic Gradient Descent, SGD)** ê³¼ **ëª¨ë©˜í…€(Momentum)** ì„ ì ìš©í•œ ê²½ì‚¬í•˜ê°•ë²•ì˜ ì°¨ì´ë¥¼ PyTorchë¡œ ë¹„êµ

---

## (1) ê¸°ë³¸ SGD

- Pytorch ì˜ 'optim' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ì„œ ìë™ìœ¼ë¡œ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ê³„ì‚° ë° ì—…ë°ì´íŠ¸

- í…ì„œ `torch.tensor`ì™€ ë„˜íŒŒì´ `numpy.array()` ê°„ ë³€í™˜ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„ í•  ê²ƒ



```python
import numpy as np
import torch
import matplotlib.pyplot as plt
from torch import optim
```


```python
# ìƒ˜í”Œ ë°ì´í„° ì„ ì–¸
sampleData1 = np.array([
    [166, 58.7],
    [176, 75.7], 
    [171, 62.1],
    [173, 70.4],
    [169, 60.1]
])

# cost function : MSE
def mse(Yp, Y):
    loss = ((Yp - Y)**2).mean()
    return loss

# x, y ë§Œë“¤ê¸°
x = sampleData1[:, 0]   # í‚¤
y = sampleData1[:, 1]   # ëª¸ë¬´ê²Œ

# x, y ê°’ì„ í‰ê·  ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ (loss ê°’ NaN ë°©ì§€âœ¨)
X = (x - x.mean())
Y = (y - y.mean())

# x,y ë³€ìˆ˜ -> í…ì„œë¡œ ë³€í™˜
X = torch.tensor(X)
Y = torch.tensor(Y)

```

### ìµœì í™” í•¨ìˆ˜ ì‚¬ìš©í•˜ê¸°

- ìµœì í™” í•¨ìˆ˜ë€? `no_grad()` ë¥¼ ì‚¬ìš©í•œ í•™ìŠµíŒŒë¼ë¯¸í„° (Weight, Bias) ì—…ë°ì´íŠ¸ ê³¼ì •ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•´ì¤Œ

> with torch.no_grad():
>    W -= lr* W.grad
>    B -= lr* B.grad

- torch.optim ì•ˆì—ëŠ” GD, SGD, SGD with momentum, Adam, ... ë“± ë‹¤ì–‘í•œ ìµœì í™” í•¨ìˆ˜ê°€ ì¡´ì¬í•¨! 

```python

# 1. ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ì´ˆê¸°ê°’ ì„¤ì •
W = torch.tensor(1., requires_grad = True)
B = torch.tensor(1., requires_grad = True)

# ì˜ˆì¸¡ í•¨ìˆ˜ ë° ì˜ˆì¸¡ê°’
def pred(X):
    y = W*X +B
    return y

# 2. hyperparmeter ì„¤ì • (í•™ìŠµë¥ , ì—í­ìˆ˜)
lr = 0.001
num_epochs = 500

optimizer = optim.SGD([W, B], lr= lr)

# 3. ì†ì‹¤ ê°’ ì €ì¥í•˜ëŠ” ë…€ì„ ë§Œë“¤ê¸°
history = np.zeros([0,2])   # row : 0 ê°œ, col: ë‘ ê°œ (epoch, loss(MSE))
```


```python
# 4. í•™ìŠµ ë£¨í”„
for epoch in range(num_epochs):

    ## ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ê³„ì‚°
    Yp = pred(X)

    ## loss êµ¬í•˜ê¸°
    loss = mse(Yp, Y)  # í…ì„œêµ¬ì¡°

    ## gradient ê³„ì‚°
    loss.backward()

    ## ê³„ì‚°ëœ í•™ìŠµ íŒŒë¼ë¯¸í„° ìë™ ì—…ë°ì´íŠ¸
    optimizer.step()

    ## W, B ì´ˆê¸°í™”
    optimizer.zero_grad()

    # 0, 10, 20, 30,,... ì—í­ë•Œ ì €ì¥í•´ë¼
    if epoch % 10 == 0:
        item = np.array([epoch, loss.item()])  # í…ì„œì—ì„œ ë„˜íŒŒì´ë¡œ ì ‘ê·¼
        history = np.vstack([history, item])   # ì•„ì´í…œ ë‚´ìš© history ì•ˆì— ì €ì¥
        print(f"Epoch: {epoch + 1}, Loss: {loss.item():.3f}")
```

```python
# 5. loss ì‹œê°í™”
plt.plot(history[:, 0], history[:, 1], label= "SGD")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()
```

![SGD_Loss](/assets/img/posts/sgd_loss.png)

---

## (2) SGD with Momentum


- ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ë™ì¼í•˜ê³  optimizer ì„¤ì •ë§Œ `momentum = 0.9` ì¶”ê°€í•˜ì—¬ ë‹¤ë¦„

- "ê´€ì„±(momentum)"ì˜ ê°œë…ì„ ë„ì…í•´, **ê²½ì‚¬ê°€ ì‘ì€ êµ¬ê°„ì—ì„œë„ í•™ìŠµì´ ë©ˆì¶”ì§€ ì•Šê³  ê¾¸ì¤€íˆ ì´ë™í•  ìˆ˜ ìˆë„ë¡** ë„ì›€

- ì¼ë°˜ SGD ì™€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ í™•ì¸ ğŸ‘‡


```python
# 1. Weight, Bias ì´ˆê¸°ê°’ ì„¤ì •
W = torch.tensor(1.0, requires_grad = True)
B = torch.tensor(1.0, requires_grad = True)

# 2. í•™ìŠµ ì„¤ì • (ë™ì¼í•œ í•™ìŠµë¥ ê³¼ ì—í­)
lr = 0.001
num_epochs = 500

#ğŸ”¸ 2.5 momentum ì„ ì¶”ê°€í•œ ìµœì í™” SGD í•¨ìˆ˜
optimizer = optim.SGD([W, B], lr= lr, momentum = 0.9)

# 3. ì†ì‹¤ ì €ì¥ìš© ë³€ìˆ˜ ë§Œë“¤ê¸°
# history for SGD w momentum
history2 = np.zeros([0, 2]) # epoch, loss
```


```python
# 4. í•™ìŠµ ë£¨í”„
for epoch in range(num_epochs):
    Yp = pred(X)
    loss = mse(Yp, Y)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    if epoch % 10 == 0:
        item = np.array([epoch, loss.item()])  
        history2 = np.vstack([history2, item])
        print(f"Epoch: {epoch + 1}, Loss: {loss.item():.4f}")
```

```python
# 5. ì†ì‹¤ ë¹„êµ ì‹œê°í™”(SGD ì™€ SGD w. momentum)
plt.plot(history[:, 0], history[:, 1], label = "SGD")
plt.plot(history2[:, 0], history2[:, 1], label = "SGD w Momentum 0.9")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
plt.show()
```
![SGD_Loss_w_Momemtum](/assets/img/posts/sgd_loss_momentum.png)

---

ğŸ”¹ ì¦‰, ê²°ê³¼ ìš”ì•½
| ìµœì í™” í•¨ìˆ˜          | íŠ¹ì§•                   | ìˆ˜ë ´ ì†ë„   |
| ------------------ | -------------------- | ------- |
| **SGD**            | ë‹¨ìˆœí•œ ê¸°ìš¸ê¸° í•˜ê°• ë°©ì‹        | ëŠë¦¼      |
| **SGD + Momentum** | ì´ì „ ì—…ë°ì´íŠ¸ ë°©í–¥ì„ ê³ ë ¤í•œ ê´€ì„± íš¨ê³¼ ì¶”ê°€ | ë¹ ë¥´ê³  ì•ˆì •ì  |
